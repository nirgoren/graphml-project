{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import PCPNetDataset\n",
    "from torch_geometric.transforms import ToSparseTensor, KNNGraph, Compose\n",
    "from normal_diffusion.data.patches import PatchDataloader\n",
    "from normal_diffusion.data.transforms import DistanceToEdgeWeight, KeepNormals\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Choose the root directory where you want to save the dataset\n",
    "root = \"../data/PCPNetDataset\"\n",
    "dataset = PCPNetDataset(\n",
    "    root=root,\n",
    "    category=\"NoNoise\",\n",
    "    split=\"train\",\n",
    "    transform=Compose([KeepNormals(), KNNGraph(k=6), DistanceToEdgeWeight(), ToSparseTensor()]),\n",
    ")\n",
    "# dataloader = PatchDataloader(dataset, batch_size=256, hops=15, transform=Compose([DistanceToEdgeWeight(), ToSparseTensor()]), limit_num_batches=1000) # can add ToSparseTensor conversion here \n",
    "# dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# dataloader = Batch.from_data_list(dataset)\n",
    "dataloader = dataset\n",
    "print(len(dataloader))\n",
    "first_collection = next(iter(dataloader))\n",
    "first_collection = first_collection.to(device)\n",
    "print(first_collection.x.shape)\n",
    "print(first_collection.adj_t)\n",
    "print(first_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from normal_diffusion.models import GCNModel\n",
    "model = GCNModel().to(device)\n",
    "t = torch.ones(first_collection.x.shape[0]).to(device)\n",
    "predicted_normals = model(graph_data=first_collection, t=t)\n",
    "print(predicted_normals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from diffusers import DDPMScheduler\n",
    "from normal_diffusion.training.training import train_diffusion\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "scheduler = DDPMScheduler(num_train_timesteps=5, beta_schedule=\"squaredcos_cap_v2\", clip_sample=False)\n",
    "# Setup TensorBoard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "train_diffusion(model=model, dataloader=dataloader, scheduler=scheduler, n_epochs=100, lr=1e-3, writer=writer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
