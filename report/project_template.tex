\documentclass{acmart}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
\newcommand{\x}{\mathbf{x}}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

 \citestyle{acmauthoryear}

%%
\title{Point Cloud Normal Estimation using Diffusion with GNNs}
\author{Nir Goren - 313452781}
\author{Yuval Reshef - 206184897}

\date{}

\setcopyright{none}

\newcommand{\instructions}[1]{\textcolor{red}{#1}\newline}
\renewcommand{\instructions}[1]{}    % comment/uncomment this line to show/hide instructions

\begin{document}

\begin{abstract}
\instructions{TL;DR of this project -  one paragraph}
Normal estimation for point clouds is an important problem in 3D computer vision and graphics, essential for tasks like denoising, surface reconstruction, and segmentation. We propose a novel framework leveraging Denoising Diffusion Probabilistic Models (DDPM) for point cloud normal estimation. By incorporating Graph Neural Networks (GNNs) as the backbone for the diffusion process, our approach effectively captures intricate geometric relationships in point clouds.
\end{abstract}
\maketitle

\section{Introduction}
\instructions{Explain the background and the problem you are trying to solve in this project - 0.5-1 page}
Estimating normals for point clouds is a fundamental challenge in 3D computer vision and computer graphics, with many practical applications. Typically, scanned point clouds provide only spatial coordinates and may be affected by issues such as varying sampling density, noise, outliers, or texture artifacts, while lacking key local surface properties like normals. High-quality normal estimation plays an important role in downstream tasks, including point cloud denoising \cite{lu2020deep,lu2020low}, surface reconstruction \cite{kazhdan2006poisson,fleishman2005robust}, and model segmentation \cite{che2018multi}.
Although normal estimation has been studied extensively, it remains an open problem. Traditional approaches often rely on techniques like Principal Component Analysis (PCA) \cite{hoppe1992surface} and Singular Value Decomposition (SVD) \cite{pauly2002efficient}. While effective for clean and simple datasets, these methods struggle with noisy data, outliers, and complex geometries. Additionally, their performance is highly sensitive to parameter tuning.
Recently, learning-based approaches are used, aiming to directly regress normals and showing promising results \cite{guerrero2018pcpnet,ben2019nesti,zhou2020geometry,wang2020neighbourhood,hashimoto2019normal}, as well as combining geometric methods with learning, such as weighted least-squares (WLS) \cite{lenssen2020deep,ben2020deepfit,zhang2022geometry,zhu2021adafit}, where point-wise weights are predicted to improve robustness and accuracy. While WLS enhances performance, estimating precise normals in complex regions remains challenging.

In this project, we propose leveraging Denoising Diffusion Probabilistic Models (DDPM) \cite{ho2020denoising} for normal estimation in point clouds. DDPM, a class of generative models known for their ability to learn complex distributions through a diffusion process, provides a robust framework to capture complex geometric relationships within local neighborhoods. By using a Graph Neural Network (GNN) as the backbone for the diffusion process in DDPM we can leverage the diffusion process for learning on non-Euclidean data, such as point clouds.

\section{Related Work}
\instructions{Literature review of related works, e.g. if you only focus on MPGNNs : Message-Passing graph neural network are a popular class of neural networks which...\cite{morris2021weisfeiler} - 0.5-1 page}
\subsection{Point Cloud Normal Estimation}
Classical methods for normal estimation in point clouds primarily rely on geometric and statistical techniques. These methods often define a local neighborhood around each point and estimate the normal vector based on the spatial arrangement of points in that neighborhood. Among the most widely used approaches are Principal Component Analysis (PCA) \cite{hoppe1992surface} and Singular Value Decomposition (SVD) \cite{pauly2002efficient}.
Both methods work similarly by choosing the direction with smallest variance. These approaches are computationally efficient and effective for clean and uniformly sampled point clouds.
However, traditional methods face significant challenges when dealing with real-world data, where point clouds are often contaminated with noise, outliers, and non-uniform sampling densities. These factors can distort the local geometry, leading to inaccurate normal estimations.

With the success of deep learning across various domains, learning-based methods for point cloud normal estimation have emerged, typically categorized into regression-based and geometry-guided approaches.
Regression based methods, used patches created from each point's neighborhood to regress the normal, this is done, for example, by utilizing 2D CNNs on the hough accumulator after performing hough transform for each normal \cite{boulch2016deep}, or on a height map generated from each patch \cite{roveri2018pointpronets,zhou2022refine}. Some methods \cite{guerrero2018pcpnet,sharma2021point} use PointNet \cite{qi2017pointnet}, a model architecture for acting directly on point-clouds, to regress the normals from local patches. Geometry-guided approaches combine learning with classical-geometric approaches, such as IterNet \cite{lenssen2020deep} and DeepFit \cite{ben2020deepfit}, which use deep learning to learn weights for weighted least squares.

More recent methods include GraphFit \cite{li2022graphfit} which uses GNNs with attention to directly predict the normals as node features, MSECNet \cite{xiu2023msecnet} which learns edge-based contextual information to predict the normals, NeAF \cite{li2023neaf} which predicts the angle offset between the ground truth normal and a randomly sampled query normal, and HSurf-Net \cite{li2022hsurf} which fits hyper-surfaces to the points in a high dimensional feature space, which are used for normal estimation.

\subsection{Denosing Diffusion Probabilistic Models}
Diffusion models, particularly Denoising Diffusion Probabilistic Models (DDPM) \cite{ho2020denoising}, have recently gained significant attention in generative modeling due to their ability to produce high-quality outputs by modeling complex data distributions. Inspired by non-equilibrium thermodynamics, DDPM gradually transforms simple noise distributions into data distributions through a series of denoising steps. This process involves a forward diffusion phase, which adds noise to the data, and a reverse denoising phase, which learns to recover the data from the noise.
Initially applied to image generation tasks, diffusion models have demonstrated state-of-the-art results in diverse domains such as audio synthesis, molecular generation, and 3D shape generation \cite{cao2024survey,yang2023diffusion}.

\subsection{Graph Neural Networks}
Graph Neural Networks (GNNs) are a powerful tool for learning non-Euclidean data, where relationships between entities can be represented as graph structures. By iteratively aggregating and propagating information between neighboring nodes, GNNs capture both local and global dependencies, making them ideal for tasks involving structured data such as social networks, molecular graphs, and 3D geometry \cite{Wu_2021,ju2024survey}.

In the context of 3D point clouds, GNNs have been widely adopted for feature learning and geometric reasoning. Methods like DGCNN \cite{wang2019dynamic} and Point-GNN \cite{shi2020point} use dynamic graph construction to capture local neighborhood relationships, enabling improved performance in classification, segmentation, and surface reconstruction tasks. Unlike traditional convolutional neural networks (CNNs), GNNs adapt naturally to irregular and unordered data, such as point clouds, by operating on graph representations.

Additionaly, using GNNs as the denoising kernel for the diffusion processes has been shown to be successful in fields such as anomaly detection \cite{ConGNN_2024} and protein generation \cite{ingraham2023illuminating}.

\section{Method}
\instructions{Begin in giving intuition to the solution you are proposing, then formally detail the method/approach you are suggesting -  1 page}
Our proposed method for normal estimation on point clouds leverages Denoising Diffusion Probabilistic Models (DDPM) with Graph Neural Networks (GNNs) as the denoising kernel. The goal is to learn a robust and accurate normal estimation model. By combining the diffusion process of DDPM with the feature learning capabilities of GNNs, we aim to capture complex geometric relationships within local neighborhoods and improve the quality of normal predictions.

\paragraph{Learning Objective}
Since GNNs excel at learning local relations, yet may struggle with global context and propagating long-range information, we chose to use "unoriented normals" as our learning objective, since they are only depndent on the local geometric neighborhood of point. Unoriented normals are defined as the vectors which are perpendicular to the tangent plane of the surface at a given point, and can be pointing eiher inwards or outwards as opposed to oriented normals which points outwards. While oriented normals are more informative, they are also more difficult to learn, as they require global context to determine the correct orientation. Since many other methods use unoriented normals as their learning objective, many methods for orienting normals (getting the correct orientation from unoriented normals) have been developed \cite{xu2023globally,gotsman2024linear}.


\paragraph{Model Architecture}
Our model consists of a 3 GNN message passing layers with attentional aggregation \cite{li2019graph}, which takes as input the 3D coordinates of the points, the noisy normals and the diffusion timestep. The message passing is done on a graph constructed by connecting edges for the points using K-nearest neighbors using the points positions in space. The attentional aggregation uses a 2 layer MPL for computing the attention scores, and a 3 layer MLP on node features before aggregating them. We use ReLU activation functions after each layer and in the attention MLPs. In each message passing layer, we augment the messages by concatenating the features of the target node, as well as sinusoidal time embeddings of the diffusion timestep, and a relative position (direction vector between the target node and the source node) similar to \cite{qi2017pointnet++}, which we project to a higher dimension using a pointwise convolution, which we have found necessary for training to converge. Using the relative position as a feature allows the model to learn the geometric relationships between the points while still being invariant to global translation and equivariant to rotation. The output of the GNN is a set of predicted normals for each point in the point cloud.


\paragraph{Training Process}
We train the model using the DDPM training process, where for each sample we draw a diffusion timestep (out of a total of 1000), apply Gaussian noise to the normals according to a noise schedule and re-normalize. We then attempt to denoise the noisy normals using the GNN. We use the following loss function:
\begin{equation}
  \mathcal{L}_{\text{unoriented}} = -\sum_i \left|n_i \cdot \hat{n}_i\right|  
\end{equation}
where $n_i$ is the ground truth normal for point $i$, which we flip with probability 0.5 (to make the model agnostic to normal orientations for better convergence during inference), and $\hat{n}_i$ is the predicted normal. The predicted normal is obtained using:
\begin{equation}
    \hat{n}_i = \frac{f(\tilde{n}_i^t, p_i, t_i)}{||f(\tilde{n}_i^t, p_i, t_i)||}
\end{equation}
where $f$ is the GNN model, $\tilde{n}_i^t$ is the noisy normal at timestep $t$, $p_i$ is the 3D position of point $i$, and $t_i$ is the diffusion timestep. We use the Adam optimizer with a learning rate of 0.001.

\paragraph{Inference}
We use DDIM sampling \cite{song2020denoising} for inference. We start with noisy normals, and run the GNN model to get the predicited normals in a similar way to the training process. We then interpolate linearly between the predicted normals and the noisy normals using a schedule that gives more weight to the predicted normals over timesteps, and repeat this process for 50 timesteps. We then use the predicted normals at the final step as the final output.

\section{Experiments and Results}
\instructions{Describe in details the experiments you conducted, the datasets you use, the evaluation metric and models/other methods you compared to, how you generated your splits / where did you take the splits from, etc. Make sure to explain every experiment you show, what is the goal of this experiment? If needed, include running time /memory report, etc.
This is also the place to include details on your implementation, e.g. which libraries did you use, and a link to public github with the code (can be anonymous github) - 1-2 pages}

\paragraph{Implementation}
We implemented our model in PyTorch and used the PyTorch-Geometric library for graph operations. Our model consists of a graph neural network with 3 layers with varying input and output dimesions. We used the ReLU activation function after each layer, a time-embedding dimension of 32 and a relative-position-embedding dimension of 12, and used K=6 for kNN. We experimented with both attentional aggregation and mean aggregation, but found that the attentional aggregation performed better. Our code is available at \url{https://github.com/nirgoren/graphml-project}.

\paragraph{Datasets}
We trained our model on the synthetic PCPNet dataset \cite{guerrero2018pcpnet} and evaluated it on the PCPNet test set. The PCPNet dataset contains 27 point clouds (8 for training and 19 for testing) sampled uniformly from meshes with 100,000 points. We also tried to incorporate the ShapeNet dataset \cite{shapenet2015} into our training data, which is considerably larger, but the performance seemed to degrade using the same training duration, so we did not include it in our final model. This might be due to a domain gap between the two datasets which may result in a slower training for models with stronger learning capabilities \cite{jin2024asymmetrical}.

We trained our model using the Adam optimzier with a batch size of 4 and learning rate of 0.001, for 6000 epochs in total, with 1000 timesteps. Training took approximately 5 hours on a single NVIDIA RTX 3090 GPU.

We conducted experiments to evaluate the performance of our model on the test set of the PCPNet dataset.

\paragraph{Evaluated Models}
We compared our model to existing deep-learning-based methods for normal estimation on point clouds, including PCPNet \cite{guerrero2018pcpnet}, Nesti-Net \cite{Ben-Shabat_2019_CVPR}, IterNet \cite{lenssen2020deep}, DeepFit \cite{ben2020deepfit}, AdaFit \cite{zhu2021adafit}, and GraphFit \cite{li2022graphfit}, as well as two geometric methods, PCA and n-jets \cite{CAZALS2005121}.
\paragraph{Evaluation Protocol}
When evaluating our method, we took the test set samples and replaced the ground truth normals with normals uniformly sampled from the unit sphere. We then ran the test set through 50 denoising steps with a DDIM sampler and using the GLIDE cosine scheduler \cite{DBLP:journals/corr/abs-2112-10741} to obtain the final predicted normals. Inference took approximately 2 seconds per point cloud on a single NVIDIA RTX 3090 GPU.
For evaluation we used the root-mean-squared-error (RMSE) of the angles (degrees) between the predicted normals and the ground truth normals.
\begin{equation}
    \text{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(\arccos(|\hat{n}_i \cdot n_i|))^2}
\end{equation}
where $\hat{n}_i$ is the predicted normal, $n_i$ is the ground truth normal for point $i$, and $(\cdot, \cdot)$ is the inner product of two vectors.

We also evaluated the robustness of our model to noise by evaluating it on a noisy version of the PCPNet dataset (where the point positions are perturbed by a small amount of noise but the ground truth normals remain the same). The results are shown in Table \ref{tab:noise_comparison}. Furthermore, we evaluated the effect of the model size on the performance of our model, as shown in Table \ref{tab:size_comparison}, the effects of different aggregation methods, as shown in Table \ref{tab:aggregation_comparison} and the effect of unoriented normal augmentation on the performance of our model, as shown in Table \ref{tab:augmentation_comparison}.
 \subsection{Results}
 \instructions{Discuss in details the results of your experiments. Did you succeed? what is the improvement \% ? provide cumulative analysis of the results. Discuss potential error, or suggest explanations to why the method failed if it failed - 
 1 page}

 \begin{table}[ht]
  \centering
  \caption{Comparison of normal estimation methods under varying levels of noise augmentation.}
  \label{tab:noise_comparison}
  \begin{tabular}{lccccccccc}
  \hline
  \textbf{Aug.} & \textbf{Ours} & \textbf{GraphFit} & \textbf{AdaFit} & \textbf{DeepFit} & \textbf{IterNet} & \textbf{Nesti-Net} & \textbf{PCPNet} & \textbf{Jet} & \textbf{PCA} \\ \hline
  w/o Noise & 11.01 & 4.45  & 5.19  & 6.51  & 6.72  & 6.99  & 9.62  & 12.25 & 12.29 \\
  $\sigma = 0.125\%$ & 35.84 & 8.74  & 9.05  & 9.21  & 9.95  & 10.11 & 11.37 & 12.84 & 12.87 \\
  $\sigma = 0.6\%$  & 59.17 & 16.05 & 16.44 & 16.72 & 17.18 & 17.63 & 18.87 & 18.33 & 18.38 \\
  $\sigma = 1.2\%$  & 60.80 & 21.64 & 21.94 & 23.12 & 21.96 & 22.28 & 23.28 & 27.68 & 27.50 \\ \hline
  \end{tabular}
  \end{table}

\begin{table}[ht]
  \centering
  \caption{Comparison of model size factor on the PCPNet test set.}
  \label{tab:size_comparison}
  \begin{tabular}{lcc}
  \hline
  \textbf{Model Size Factor K} & \textbf{64} & \textbf{128} \\ \hline
  RMSE & 11.01 & 20.77 \\ \hline
  \end{tabular}
  \end{table}

\begin{table}[ht]
  \centering
  \caption{Comparison of unoriented normal augmentation (where the ground truth normals are randomly flipped during training) on the PCPNet test set.}
  \label{tab:augmentation_comparison}
  \begin{tabular}{lcc}
  \hline
  \textbf{Augmentation} & \textbf{With} & \textbf{Without} \\ \hline
  RMSE & 11.01 & 12.11 \\ \hline
  \end{tabular}
  \end{table}
\begin{table}[ht]
  \centering
  \caption{Comparison of aggregation method on the PCPNet test set.}
  \label{tab:aggregation_comparison}
  \begin{tabular}{lccc}
  \hline
  \textbf{Aggregation} & \textbf{attentional} & \textbf{mean} & \textbf{max} \\ \hline
  RMSE & 11.01 & 15.50 & 12.10 \\ \hline
  \end{tabular}
  \end{table}
Ultimately, on the clean test set, while our model managed to perform better than the geometric methods, it failed to reach the performance of competing deep learning based methods. Our method also does not generalize well to the noisy test sets. There may be several explanations as to why this is the case. Some of those methods, such as GraphFit, don't directly output the predicted normals but rather a set of coefficients that are used to geometrically fit a normal to the point cloud at a query point. This approach may be more stable than directly predicting the normals \cite{zhu2021adafit}, however it does not fit our proposed regime of denoising a noisy feature space using graph neural networks as the denoising backbone. Additionally, as mentioned above, during training and inference at each timestep during the diffusion process we add Gaussian noise to the normals and renormalize the result. This introduces some differences between the diffusion process we use and the classical mathematically sound diffusion process described in \cite{ho2020denoising}.
Lastly, we note that by scaling up the neighborhood size $K$ for k-NN (e.g. GraphFit used $K=256,500,700$), the model size, and the data we might achieve significantly better results, however these changes, especially the increase in $K$, lead to a significant increase in the computational cost and memory consumption of training the model, and therefore we were unable to train the model at such a scale using the computational resource available to us and the time scope of this project.


\section{Future work}
\instructions{Suggest 1-2 to continue your work or futhure improve you work.
one-two paragraphs}
In designing our model we tried to be general and flexible, so that it can be easily adapted to other tasks. It might be interesing to see how our model performs on other tasks that involve predicting continuous features of nodes in graphs, such as color prediction of colored point clouds. Our approach can also potentially be used for other tasks such as denoising graph features, or tasks that involve generating diverse samples (of graphs) from a given distribution, for which diffusion models are known to be well-suited.
Finally, for the task of normal prediction, using flow matching \cite{lipman2023flowmatchinggenerativemodeling} on the sphere instead of diffusion with normalization might be a more appropriate method for denoising the normals.

\section{Conclusion}
\instructions{Conclude the project - what did you try to achieve, how you tried to achieve it, and did you manage to achieve that?  - one paragraph}
We proposed a novel method for normal estimation on point clouds using diffusion on the node features with graph neural networks, and evaluated its performance to see how competitive it is with existing methods. We showed that our method outperforms geometric methods but does not reach the performance of competing deep learning based methods, and does not generalize well to noisy test sets. We also discussed potential reasons for this and suggested future work.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}
\end{document}

